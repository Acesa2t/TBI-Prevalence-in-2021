#'===================================================================================================================#
#'
#' This script takes annual risk of infection (ARI) values developed by Pete Dodd and Rein Houben and 
#' generates force of infection (FOI) estimates for differing population groups (by age, year of arrival 
#' and country of birth), which can then be converted to probabilities/risk of infection and combined 
#' with census datasets to arrive at prevalence of TB infection estimates for a particular setting.
#' The script will  calculate the median hazard for each population group in the census and, additionally, will provide lower and 
#' upper percentile estimates, as defined by the following
#' objects.
#' These are also combined with TB data to provide estimates of reactivation rates/risks.
#'
#' INPUTS:
#'  - ARTI estimates generated by Pete Dodd and Rein Houben ("5000repLARI.Rdata" and "200repLARI.Rdata")
#'  - Census data by age, year of arrival, and country of birth. This file needs to be cleaned
#'  and reshaped, if necessary, with the "CleanseCensus" function to create a dataset with the
#'  following columns:
#'      -  NUMP - Number of persons in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  YOBP - Year of birth of population group
#'      -  BPLP - Birth country of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#'      -  CNSY - Census year
#'  - TB data by year of notification, age, year of arrival, and country of birth. This file needs to be cleaned
#'  and reshaped, if necessary, with the "CleanseTBdata" function to create a dataset with the
#'  following columns:
#'      -  year - Year of notification
#'      -  poptb - Number of TB cases in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#' 
#' OUTPUTS:
#' - A master table of all TB infection probabilities and outcomes, 
#' stored in the outputs path specified below (path.out).
#'      -  NUMP - Number of persons in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  YOBP - Year of birth of population group
#'      -  BPLP - Birth country of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#'      -  CNSY - Census year
#'      -  LTBP - Number of in the population estimated to have been infected
#'      -  PROB - Probability/risk of infection in the population group
#' 
#' Author: Katie Dale and Milinda Abayawardana
#' Date created: 2016-2021
#'===================================================================================================================#

rm(list = ls(all.names = TRUE)) # Clears all objects includes hidden objects.
gc() # Frees up memory and report the memory usage.

#' LOAD REQUIRED LIBRARIES ==========================================================================================#

library(data.table)
library(tidyverse)
library(reshape2)
library(countrycode)

#' DEFINE USEFUL OBJECTS (INPUT & OUTPUT PATHS, FUNCTIONS, STUDY PERIOD ETC) ========================================#

#' The iso3 value for the country from which the census data is from

census.iso3 <- "CAN"

census.year <- 2021

#' This script will calculate the median hazard for each population
#' group in the census and, additionally, will provide lower and 
#' upper percentile estimates, as defined by the following
#' objects.
low.percentile <- 0.025
high.percentile <- 0.975

#' Data inputs file path
path.in <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"

#' Output file path
path.out <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"

#' Source all functions, which are located within the "Functions" file.
source(paste0(path.in, "Functions3 iso3.R"))

#' INPUTS ===========================================================================================================#

#' Load the hazard data from Houben & Dodd
# filename <- paste0(path.in, "5000repLARI.Rdata")
# 
# tbhaz.5000rep <- load(filename)
# tbhaz.5000rep <- LARI
# rm(LARI)

filename <- paste0(path.in, "200repLARI.Rdata")
load(filename)

filename2 <- paste0(path.in, "fcst.Rdata")
load(filename2)

tbhaz.200rep.bind <- rbind(rundata, fcst)
tbhaz.200rep <- as.data.table(tbhaz.200rep.bind)
rm(rundata)
View(tbhaz.200rep)

#' Load the census data 
census <- read.csv(paste0(path.in, "census_classified_2021 copy.csv"), header = T)
View(census)
census <- census%>%select(-ID, -X, -YARP_GROUPS,-AGE_BANDS )
colnames(census) <- c("ISO3", "WHO_R","CNSY", "BPLP","YARP","AGEP","YOBP","NUMP")

# Remove ISO3s that are not in Houben and Dodd dataset or they will give a result of 0 LTBP while including the population. This will lead to an underestimate of prevalence

#census <- census%>%filter(!ISO3%in%c("FRO", "GGY", "GIB", "GLP", "GUF", "IMN", "JEY", "MTQ", "SPM", "TWN"))

census <- census%>%filter(!ISO3%in%c("FLK", "GIB", "GLP", "GUF", "LIE", "MTQ"))

View(census)
# census <- read.csv(paste0(path.in, "Australia 2006.csv"), skip = 9, header = T)
# census <- read.csv(paste0(path.in, "Australia 2011.csv"), skip = 9, header = T)
#View(census)
#' Load TB data 
tb <- read.csv(paste0(path.in, "NNDSS skeleton.csv"), header = T)

#' DATA PREP ========================================================================================================#

#' Creating cumulative FOIs and adjusting for census year.
#' Also expanding the table's year range ( 1889 to 2016).
tbhaz.200rep <- tbhazprep.function(tbhaz.200rep)
View(tbhaz.200rep)

# tbhaz.5000rep <- tbhazprep.function(tbhaz.5000rep)

#' Clean the census data so that it has the following columns
#' AGEP, YARP, cob, NUMP, CNSY, YOBP and ISO3
# census <- CleanseCensus(census)

#' Clean the TB data so that it has the following columns
#' AGEP, YARP, cob, NUMP, year, YOBP and ISO3
tb <- CleanseTBdata(tb)

tb <- subset(tb, year == census.year)
tb <- as.data.table(tb)
tb[, CNSY := as.numeric(year)]

#' Checking if there are any countries that don't have an 
#' ISO3 match from Houben and Dodd.
setdiff(census$ISO3, tbhaz.200rep$iso3) 
View(census)
setdiff(tb$ISO3, census$ISO3) 

setdiff(tb$ISO3, tbhaz.200rep$iso3) 

setdiff(census$ISO3, tbhaz.200rep$iso3) #' All countries in the census data are captured in Houben & Dodd data.

#' Create a master look-up table of all probabilities of infection 
#' for each population group, by using the census and tb tables 
#' to get a list of unique ISO codes.
master.Prob <- CreateProbTables()

#' ==================edited out the ISO3 look-up for 5000 vs 200 rep
#' Subset the look-up table by ISO3 depending on whether the relevant tbhaz values 
#' are in the tbhaz.200 or tbhaz.5000 data set.
# prob.Inf5000 <- master.Prob[ISO3 == "CHN" | ISO3 == "GBR" | ISO3 == "IND" |
#                               ISO3 == "MYS" | ISO3 == "PHL" | ISO3 == "VNM"]
# 
# prob.Inf200 <- master.Prob[ ISO3 != census.iso3 & ISO3 != "CHN" & ISO3 != "GBR" 
#                             & ISO3 != "IND" & ISO3 != "MYS" & ISO3 != "PHL" 
#                             & ISO3 != "VNM"]

prob.Inf200 <- master.Prob[ !(ISO3 %in% c(census.iso3))] 

#' Also create a separate look-up table for the locally born.
prob.Inf.local <- master.Prob[ISO3 == census.iso3]

#' Tidy
rm(master.Prob)

#' The following function calculates hazards for the locally
#' born population (prob.Inf.local). The percentiles
#' that are required can be defined earlier in the script.

prob.Inf.local <- TBhazard.calc.function.local.born(prob.Inf.local, tbhaz.200rep)

#' Saving and removing file (memory management)
saveRDS(prob.Inf.local, file = paste0(path.out, "prob.Inf.local.rds"))
rm(prob.Inf.local)

#' The following function calculates hazards for the population
#' groups in the prob.Inf200 look-up table. The percentiles
#' that are required can be defined earlier in the script.
#' Because the hazard calculations are quite memory intensive, 
#' I've split the data into groups by year of birth, before 
#' running the function on it, so the chunks are more manageable.
#' Then the separate chunks are subsequently bound together again.

prob.Inf200[YOBP < 1930 , YOBPgroup := 1]
prob.Inf200[YOBP > 1929 & YOBP < 1960 , YOBPgroup := 2]
prob.Inf200[YOBP > 1959 & YOBP < 1980 , YOBPgroup := 3]
prob.Inf200[YOBP > 1979 & YOBP < 2000 , YOBPgroup := 4]
prob.Inf200[YOBP > 1999 & YOBP < 2010 , YOBPgroup := 5]
prob.Inf200[YOBP > 2009 , YOBPgroup := 6]

yob.split <- split(prob.Inf200, prob.Inf200$YOBPgroup)

yob.split <- lapply(yob.split, TBhazard.calc.function.overseas.born, tbhaz.200rep)
View(yob.split[[1]])

prob.Inf200 <- do.call("rbind", yob.split)

View(prob.Inf200)
#' Tidy
#'
rm(yob.split)

#' Saving and removing file (memory management)
saveRDS(prob.Inf200, file = paste0(path.out, "prob.Inf200.rds"))
View(prob.Inf200)
#' Tidy
rm(prob.Inf200)

#' Repeat the same as above for the 5000rep look-up table.
#' However, with this table it is simplest to split it by ISO3, 
#' rather than year of birth (because there are only six ISO3).

#=================Removing iso3.split=============================
#iso3.split <- split(prob.Inf5000, prob.Inf5000$ISO3)
#' 
#iso3.split <- lapply(iso3.split, TBhazard.calc.function.overseas.born, tbhaz.5000rep)
#' 
#prob.Inf5000 <- do.call("rbind", iso3.split)
#' 
#' #' Saving and removing file (memory management)
#saveRDS(prob.Inf5000, file = paste0(path.out, "prob.Inf5000.rds"))
#rm(prob.Inf5000, iso3.split)

#' Order the census data.table.
census <- setorder(census, ISO3, YOBP, YARP)

#' Load the look-up tables back in.
prob.Inf200 <- readRDS(paste0(path.out, "prob.Inf200.rds"))
#prob.Inf5000 <- readRDS(paste0(path.out, "prob.Inf5000.rds"))
prob.Inf.local <- readRDS(paste0(path.out, "prob.Inf.local.rds"))

#' Bind the look-up tables altogether to make the master look-up.
prob.Inf <- rbind(prob.Inf.local, prob.Inf200, fill = T)

#' Tidy ==========EDITED OUT prob.Inf5000
rm(prob.Inf.local, prob.Inf200)

#' Calculating the probability of infection (PROB)
#' from the hazards.
#' 
rm(tbhaz.200rep)

prob.Inf[, negPROB := .(mapply('*',-1, H, SIMPLIFY = F)),]
prob.Inf[, H := NULL,]
prob.Inf[, prePROB := .(mapply(exp, negPROB, SIMPLIFY = F)),]
prob.Inf[, negPROB := NULL,]
prob.Inf[, PROB := .(mapply('-', 1, prePROB, SIMPLIFY = F)),]
prob.Inf[, prePROB := NULL,]

View(prob.Inf)
# prob.Inf[, PROB.med := 1 - exp(-(H.med))]
# prob.Inf[, PROB.low := 1 - exp(-(H.low))]
# prob.Inf[, PROB.high := 1 - exp(-(H.high))]

#' Calculating the number of individuals in the population estimated 
#' to have been infected (LTBP).

census <- as.data.table(census)
census[prob.Inf, LTBP := .(mapply('*', NUMP, PROB, SIMPLIFY = F)), on = .(ISO3, YOBP, YARP),]
#View(census)
# census[prob.Inf, LTBP := NUMP * PROB.med, on = .(ISO3, YOBP, YARP)]
# census[prob.Inf, LTBP.low := NUMP * PROB.low, on = .(ISO3, YOBP, YARP)]
# census[prob.Inf, LTBP.high := NUMP * PROB.high, on = .(ISO3, YOBP, YARP)]

census_na <- na.omit(census)
#View(prob.Inf)
length(unique(census_na$ISO3))

#' Check the number missing LTBP information
census[is.na(LTBP), sum(NUMP)]

#' Check the percentage missing LTBP information
#' (some investigation may need to be done to work out
#' why these population groups have missing data. It
#' could be because some countries of birth were not
#' mapped to an ISO3 value).
census[is.na(LTBP), sum(NUMP)]/census[, sum(NUMP)] * 100

#' Merge in the TB data
#census <- merge(census, tb, by = c("AGEP", "ISO3", "CNSY", "YARP"), all.x = T)
#View(census)

#write.csv(census,"/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/Outputs/2021 estimates_iso3.csv", row.names = FALSE)




#' DATA OUTPUTS =======================================================================================================#

#' Save all the objects that haven't yet been saved.
saveRDS(prob.Inf, file = paste0(path.out, "2021.prob.Inf_iso3.rds"))

saveRDS(census, file = paste0(path.out, "2021_estimates_iso3.rds"))

# May have removed YOBP > YARP too early
